{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e43a3963",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, f1_score\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "659f878f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "\n",
    "# 1. Data Preprocessing\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),  # Resize for efficiency in FHE\n",
    "    transforms.Grayscale(),       # Convert to grayscale for single-channel input\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))  # Normalize to [-1, 1] for HE compatibility\n",
    "])\n",
    "\n",
    "# Load dataset\n",
    "data_dir = 'C:\\\\Users\\\\Harshavardan pd\\\\OneDrive\\\\Desktop\\\\new crypt\\\\COVID-19_Radiography_Dataset'\n",
    "dataset = datasets.ImageFolder(\n",
    "    root=data_dir,\n",
    "    transform=data_transforms,\n",
    "    is_valid_file=lambda path: path.endswith(('.png', '.jpg', '.jpeg')) and 'images' in path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f891861a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Programmatic Train/Validation/Test Split\n",
    "indices = list(range(len(dataset)))\n",
    "labels = [dataset.targets[i] for i in indices]\n",
    "\n",
    "# First, split into train+val (80%) and test (20%)\n",
    "train_val_indices, test_indices = train_test_split(\n",
    "    indices, test_size=0.2, stratify=labels, random_state=42\n",
    ")\n",
    "# Then, split train+val into train (70% of total) and validation (10% of total)\n",
    "train_indices, val_indices = train_test_split(\n",
    "    train_val_indices, test_size=0.125, stratify=[labels[i] for i in train_val_indices], random_state=42\n",
    ")\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "val_sampler = SubsetRandomSampler(val_indices)\n",
    "test_sampler = SubsetRandomSampler(test_indices)\n",
    "\n",
    "train_loader = DataLoader(dataset, batch_size=32, sampler=train_sampler, num_workers=4, pin_memory=True)\n",
    "val_loader = DataLoader(dataset, batch_size=32, sampler=val_sampler, num_workers=4, pin_memory=True)\n",
    "test_loader = DataLoader(dataset, batch_size=32, sampler=test_sampler, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1373075e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['COVID', 'Lung_Opacity', 'Normal', 'Viral Pneumonia']\n",
      "Train set size: 14815, Validation set size: 2117, Test set size: 4233\n"
     ]
    }
   ],
   "source": [
    "# Print dataset info\n",
    "print(f\"Classes: {dataset.classes}\")\n",
    "print(f\"Train set size: {len(train_indices)}, Validation set size: {len(val_indices)}, Test set size: {len(test_indices)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "765ac5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Define HE-Compatible CNN\n",
    "class HECNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(HECNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.AvgPool2d(2, 2)  # AvgPool for better HE compatibility\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.fc1 = nn.Linear(32 * 16 * 16, 128)\n",
    "        self.fc2 = nn.Linear(128, 4)  # 4 classes: COVID, Lung_Opacity, Normal, Viral Pneumonia\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = x * x  # Square activation (HE-friendly)\n",
    "        x = self.pool(x)\n",
    "        x = self.conv2(x)\n",
    "        x = x * x\n",
    "        x = self.pool(x)\n",
    "        x = x.view(-1, 32 * 16 * 16)\n",
    "        x = self.fc1(x)\n",
    "        x = x * x\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b76df169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# 4. Setup Model, Loss, and Optimizer\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "model = HECNN().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cbb1f31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Validation Function\n",
    "def validate_model(model, val_loader, criterion):\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    val_loss = val_loss / len(val_loader)\n",
    "    val_accuracy = 100 * correct / total\n",
    "    return val_loss, val_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3cfaebc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Training Function with Progress Bar and Early Stopping\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, epochs=10, patience=3):\n",
    "    model.train()\n",
    "    best_val_loss = float('inf')\n",
    "    train_loss_history = []\n",
    "    val_loss_history = []\n",
    "    val_accuracy_history = []\n",
    "    epochs_without_improvement = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\")\n",
    "        for images, labels in progress_bar:\n",
    "            images, labels = images.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            progress_bar.set_postfix({'batch_loss': loss.item()})\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        train_loss_history.append(epoch_loss)\n",
    "\n",
    "        # Validate after each epoch\n",
    "        val_loss, val_accuracy = validate_model(model, val_loader, criterion)\n",
    "        val_loss_history.append(val_loss)\n",
    "        val_accuracy_history.append(val_accuracy)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}, Train Loss: {epoch_loss:.4f}, Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.2f}%\")\n",
    "\n",
    "        # Save model if validation loss improves\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), 'covid_radiograph_model_best.pth')\n",
    "            print(f\"Model saved (improved val loss: {best_val_loss:.4f})\")\n",
    "            epochs_without_improvement = 0\n",
    "        else:\n",
    "            epochs_without_improvement += 1\n",
    "\n",
    "        # Early stopping\n",
    "        if epochs_without_improvement >= patience:\n",
    "            print(f\"Early stopping triggered after {epoch+1} epochs (no improvement in validation loss for {patience} epochs)\")\n",
    "            break\n",
    "\n",
    "    return train_loss_history, val_loss_history, val_accuracy_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ddafe82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 7. Evaluation Function with Precision and F1 Score\n",
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    accuracy = 100 * sum(np.array(all_preds) == np.array(all_labels)) / len(all_labels)\n",
    "    precision = precision_score(all_labels, all_preds, average='macro', zero_division=0)\n",
    "    f1 = f1_score(all_labels, all_preds, average='macro', zero_division=0)\n",
    "\n",
    "    print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
    "    print(f\"Test Precision (macro): {precision:.4f}\")\n",
    "    print(f\"Test F1 Score (macro): {f1:.4f}\")\n",
    "    return accuracy, precision, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a472320e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████| 463/463 [00:19<00:00, 23.21it/s, batch_loss=0.377]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 0.7214, Val Loss: 0.5516, Val Accuracy: 77.75%\n",
      "Model saved (improved val loss: 0.5516)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|██████████| 463/463 [00:20<00:00, 22.98it/s, batch_loss=0.253]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Train Loss: 0.5213, Val Loss: 0.4493, Val Accuracy: 81.91%\n",
      "Model saved (improved val loss: 0.4493)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|██████████| 463/463 [00:20<00:00, 22.14it/s, batch_loss=0.434]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Train Loss: 0.4316, Val Loss: 0.4434, Val Accuracy: 83.23%\n",
      "Model saved (improved val loss: 0.4434)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|██████████| 463/463 [00:19<00:00, 23.46it/s, batch_loss=0.344]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Train Loss: 0.3831, Val Loss: 0.4372, Val Accuracy: 83.28%\n",
      "Model saved (improved val loss: 0.4372)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|██████████| 463/463 [00:21<00:00, 21.82it/s, batch_loss=0.407] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Train Loss: 0.3467, Val Loss: 0.4578, Val Accuracy: 84.18%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|██████████| 463/463 [00:20<00:00, 22.62it/s, batch_loss=0.543] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Train Loss: 0.3104, Val Loss: 0.4266, Val Accuracy: 84.41%\n",
      "Model saved (improved val loss: 0.4266)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|██████████| 463/463 [00:19<00:00, 23.58it/s, batch_loss=0.239] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Train Loss: 0.2890, Val Loss: 0.4526, Val Accuracy: 83.75%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|██████████| 463/463 [00:19<00:00, 23.59it/s, batch_loss=0.326] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Train Loss: 0.2717, Val Loss: 0.4307, Val Accuracy: 84.70%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|██████████| 463/463 [00:19<00:00, 23.68it/s, batch_loss=0.221] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Train Loss: 0.2363, Val Loss: 0.4206, Val Accuracy: 86.40%\n",
      "Model saved (improved val loss: 0.4206)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|██████████| 463/463 [00:19<00:00, 23.62it/s, batch_loss=0.161] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Train Loss: 0.2081, Val Loss: 0.4553, Val Accuracy: 84.98%\n",
      "Train Loss History: ['0.7214', '0.5213', '0.4316', '0.3831', '0.3467', '0.3104', '0.2890', '0.2717', '0.2363', '0.2081']\n",
      "Validation Loss History: ['0.5516', '0.4493', '0.4434', '0.4372', '0.4578', '0.4266', '0.4526', '0.4307', '0.4206', '0.4553']\n",
      "Validation Accuracy History: ['77.75%', '81.91%', '83.23%', '83.28%', '84.18%', '84.41%', '83.75%', '84.70%', '86.40%', '84.98%']\n",
      "Test Accuracy: 84.72%\n",
      "Test Precision (macro): 0.8636\n",
      "Test F1 Score (macro): 0.8557\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 8. Train and Evaluate\n",
    "# Change the 'epochs' parameter HERE to adjust the number of training epochs\n",
    "# Set to 10 to allow early stopping to find the optimal epoch (likely around 5-7 based on previous results)\n",
    "train_loss_history, val_loss_history, val_accuracy_history = train_model(model, train_loader, val_loader, criterion, optimizer, epochs=10, patience=3)\n",
    "print(\"Train Loss History:\", [f\"{loss:.4f}\" for loss in train_loss_history])\n",
    "print(\"Validation Loss History:\", [f\"{loss:.4f}\" for loss in val_loss_history])\n",
    "print(\"Validation Accuracy History:\", [f\"{acc:.2f}%\" for acc in val_accuracy_history])\n",
    "accuracy, precision, f1 = evaluate_model(model, test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dd340ddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final model saved as 'covid_radiograph_model_final.pth'\n"
     ]
    }
   ],
   "source": [
    "# Save final model\n",
    "torch.save(model.state_dict(), 'covid_radiograph_model_final.pth')\n",
    "print(\"Final model saved as 'covid_radiograph_model_final.pth'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
